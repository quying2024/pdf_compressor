"""
hOCR æ–‡ä»¶åˆ†æå’Œä¼˜åŒ–å·¥å…·

åŠŸèƒ½ï¼š
1. åˆ†æ hOCR æ–‡ä»¶ç»“æ„
2. å®éªŒæ€§åˆ é™¤ä¸åŒéƒ¨åˆ†
3. æµ‹é‡æ–‡ä»¶å¤§å°å˜åŒ–
4. è¯„ä¼°å¯¹ PDF ç”Ÿæˆçš„å½±å“
"""

import re
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Tuple
import logging

class HocrAnalyzer:
    """hOCR æ–‡ä»¶åˆ†æå™¨"""
    
    def __init__(self, hocr_file: Path):
        self.hocr_file = Path(hocr_file)
        self.original_size = self.hocr_file.stat().st_size
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(self.hocr_file, 'r', encoding='utf-8') as f:
            self.content = f.read()
        
        print(f"ğŸ“„ åŸå§‹ hOCR æ–‡ä»¶: {self.hocr_file.name}")
        print(f"ğŸ“Š åŸå§‹å¤§å°: {self.original_size / 1024 / 1024:.2f} MB")
        print(f"ğŸ“ åŸå§‹è¡Œæ•°: {len(self.content.splitlines())}")
    
    def analyze_structure(self) -> Dict:
        """åˆ†æ hOCR æ–‡ä»¶çš„åŸºæœ¬ç»“æ„"""
        print("\n" + "="*70)
        print("ğŸ” hOCR æ–‡ä»¶ç»“æ„åˆ†æ")
        print("="*70)
        
        analysis = {
            'total_size': self.original_size,
            'total_lines': len(self.content.splitlines()),
            'elements': {}
        }
        
        # åˆ†æå„ç§ HTML æ ‡ç­¾
        tags = [
            ('ocr_page', 'é¡µé¢å®¹å™¨'),
            ('ocr_carea', 'å†…å®¹åŒºåŸŸ'),
            ('ocr_par', 'æ®µè½'),
            ('ocr_line', 'æ–‡æœ¬è¡Œ'),
            ('ocrx_word', 'å•è¯/è¯ç»„'),
        ]
        
        for tag_class, description in tags:
            pattern = rf"class=['\"].*?{tag_class}.*?['\"]"
            matches = re.findall(pattern, self.content)
            analysis['elements'][tag_class] = {
                'count': len(matches),
                'description': description
            }
            print(f"  ğŸ“Œ {tag_class:15} ({description:10}): {len(matches):6} ä¸ª")
        
        # åˆ†ææ–‡æœ¬å†…å®¹å¤§å°
        text_pattern = r'<span[^>]*?ocrx_word[^>]*?>([^<]+)</span>'
        text_matches = re.findall(text_pattern, self.content)
        total_text_size = sum(len(text.encode('utf-8')) for text in text_matches)
        
        print(f"\n  ğŸ’¬ æ–‡æœ¬å†…å®¹:")
        print(f"     - å•è¯æ•°é‡: {len(text_matches)}")
        print(f"     - æ–‡æœ¬å¤§å°: {total_text_size / 1024:.2f} KB")
        print(f"     - å æ¯”: {total_text_size / self.original_size * 100:.1f}%")
        
        analysis['text_content'] = {
            'word_count': len(text_matches),
            'text_size': total_text_size,
            'percentage': total_text_size / self.original_size * 100
        }
        
        # åˆ†æ bbox ä¿¡æ¯
        bbox_pattern = r"bbox \d+ \d+ \d+ \d+"
        bbox_matches = re.findall(bbox_pattern, self.content)
        bbox_size = sum(len(bbox.encode('utf-8')) for bbox in bbox_matches)
        
        print(f"\n  ğŸ“ åæ ‡ä¿¡æ¯ (bbox):")
        print(f"     - bbox æ•°é‡: {len(bbox_matches)}")
        print(f"     - bbox å¤§å°: {bbox_size / 1024:.2f} KB")
        print(f"     - å æ¯”: {bbox_size / self.original_size * 100:.1f}%")
        
        analysis['bbox_info'] = {
            'count': len(bbox_matches),
            'size': bbox_size,
            'percentage': bbox_size / self.original_size * 100
        }
        
        return analysis
    
    def create_empty_hocr(self, output_file: Path) -> Tuple[Path, int]:
        """
        åˆ›å»ºç©º hOCR - åˆ é™¤æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼Œä¿ç•™ç»“æ„
        
        ç­–ç•¥ï¼šåˆ é™¤ <span class="ocrx_word"> æ ‡ç­¾å†…çš„æ–‡æœ¬å†…å®¹
        """
        print("\n" + "="*70)
        print("ğŸ§ª å®éªŒ 1: åˆ›å»ºç©º hOCRï¼ˆåˆ é™¤æ–‡æœ¬å†…å®¹ï¼‰")
        print("="*70)
        
        # åˆ é™¤ ocrx_word æ ‡ç­¾å†…çš„æ–‡æœ¬å†…å®¹
        empty_content = re.sub(
            r'(<span[^>]*?ocrx_word[^>]*?>)([^<]+)(</span>)',
            r'\1\3',  # ä¿ç•™å¼€å§‹å’Œç»“æŸæ ‡ç­¾ï¼Œåˆ é™¤æ–‡æœ¬
            self.content
        )
        
        output_file.write_text(empty_content, encoding='utf-8')
        new_size = output_file.stat().st_size
        reduction = self.original_size - new_size
        percentage = (reduction / self.original_size) * 100
        
        print(f"  âœ… å·²åˆ›å»º: {output_file.name}")
        print(f"  ğŸ“Š æ–°å¤§å°: {new_size / 1024 / 1024:.2f} MB")
        print(f"  ğŸ“‰ å‡å°‘: {reduction / 1024 / 1024:.2f} MB ({percentage:.1f}%)")
        
        return output_file, new_size
    
    def create_minimal_hocr(self, output_file: Path) -> Tuple[Path, int]:
        """
        åˆ›å»ºæœ€å° hOCR - åªä¿ç•™é¡µé¢ç»“æ„å’Œ bbox
        
        ç­–ç•¥ï¼šåˆ é™¤æ‰€æœ‰æ–‡æœ¬å†…å®¹å’Œä¸å¿…è¦çš„å±æ€§
        """
        print("\n" + "="*70)
        print("ğŸ§ª å®éªŒ 2: åˆ›å»ºæœ€å° hOCRï¼ˆåªä¿ç•™å¿…è¦ç»“æ„ï¼‰")
        print("="*70)
        
        minimal_content = self.content
        
        # æ­¥éª¤1: åˆ é™¤æ–‡æœ¬å†…å®¹
        minimal_content = re.sub(
            r'(<span[^>]*?ocrx_word[^>]*?>)([^<]+)(</span>)',
            r'\1\3',
            minimal_content
        )
        
        # æ­¥éª¤2: ç®€åŒ– title å±æ€§ï¼ˆåªä¿ç•™ bboxï¼‰
        def simplify_title(match):
            full_title = match.group(1)
            bbox_match = re.search(r'bbox \d+ \d+ \d+ \d+', full_title)
            if bbox_match:
                return f'title="{bbox_match.group()}"'
            return match.group(0)
        
        minimal_content = re.sub(
            r'title="([^"]*)"',
            simplify_title,
            minimal_content
        )
        
        output_file.write_text(minimal_content, encoding='utf-8')
        new_size = output_file.stat().st_size
        reduction = self.original_size - new_size
        percentage = (reduction / self.original_size) * 100
        
        print(f"  âœ… å·²åˆ›å»º: {output_file.name}")
        print(f"  ğŸ“Š æ–°å¤§å°: {new_size / 1024 / 1024:.2f} MB")
        print(f"  ğŸ“‰ å‡å°‘: {reduction / 1024 / 1024:.2f} MB ({percentage:.1f}%)")
        
        return output_file, new_size
    
    def create_no_words_hocr(self, output_file: Path) -> Tuple[Path, int]:
        """
        åˆ›å»ºæ— å•è¯ hOCR - åˆ é™¤æ‰€æœ‰ ocrx_word æ ‡ç­¾
        
        ç­–ç•¥ï¼šå®Œå…¨ç§»é™¤ <span class="ocrx_word"> æ ‡ç­¾
        """
        print("\n" + "="*70)
        print("ğŸ§ª å®éªŒ 3: åˆ›å»ºæ— å•è¯ hOCRï¼ˆåˆ é™¤ ocrx_word æ ‡ç­¾ï¼‰")
        print("="*70)
        
        # åˆ é™¤æ•´ä¸ª ocrx_word span æ ‡ç­¾
        no_words_content = re.sub(
            r'<span[^>]*?ocrx_word[^>]*?>.*?</span>\s*',
            '',
            self.content
        )
        
        output_file.write_text(no_words_content, encoding='utf-8')
        new_size = output_file.stat().st_size
        reduction = self.original_size - new_size
        percentage = (reduction / self.original_size) * 100
        
        print(f"  âœ…å·²åˆ›å»º: {output_file.name}")
        print(f"  ğŸ“Š æ–°å¤§å°: {new_size / 1024 / 1024:.2f} MB")
        print(f"  ğŸ“‰ å‡å°‘: {reduction / 1024 / 1024:.2f} MB ({percentage:.1f}%)")
        
        return output_file, new_size
    
    def create_no_lines_hocr(self, output_file: Path) -> Tuple[Path, int]:
        """
        åˆ›å»ºæ— æ–‡æœ¬è¡Œ hOCR - åˆ é™¤æ‰€æœ‰ ocr_line æ ‡ç­¾
        
        ç­–ç•¥ï¼šç§»é™¤ <span class="ocr_line"> æ ‡ç­¾åŠå…¶å†…å®¹
        """
        print("\n" + "="*70)
        print("ğŸ§ª å®éªŒ 4: åˆ›å»ºæ— æ–‡æœ¬è¡Œ hOCRï¼ˆåˆ é™¤ ocr_line æ ‡ç­¾ï¼‰")
        print("="*70)
        
        # åˆ é™¤æ•´ä¸ª ocr_line span æ ‡ç­¾
        no_lines_content = re.sub(
            r'<span[^>]*?ocr_line[^>]*?>.*?</span>\s*',
            '',
            self.content,
            flags=re.DOTALL
        )
        
        output_file.write_text(no_lines_content, encoding='utf-8')
        new_size = output_file.stat().st_size
        reduction = self.original_size - new_size
        percentage = (reduction / self.original_size) * 100
        
        print(f"  âœ… å·²åˆ›å»º: {output_file.name}")
        print(f"  ğŸ“Š æ–°å¤§å°: {new_size / 1024 / 1024:.2f} MB")
        print(f"  ğŸ“‰ å‡å°‘: {reduction / 1024 / 1024:.2f} MB ({percentage:.1f}%)")
        
        return output_file, new_size
    
    def show_sample(self, lines: int = 50):
        """æ˜¾ç¤º hOCR æ–‡ä»¶çš„æ ·æœ¬å†…å®¹"""
        print("\n" + "="*70)
        print(f"ğŸ“ hOCR æ–‡ä»¶æ ·æœ¬ï¼ˆå‰ {lines} è¡Œï¼‰")
        print("="*70)
        
        content_lines = self.content.splitlines()
        for i, line in enumerate(content_lines[:lines], 1):
            print(f"{i:3}: {line}")
        
        if len(content_lines) > lines:
            print(f"\n... (çœç•¥ {len(content_lines) - lines} è¡Œ)")


def run_hocr_experiments(hocr_file: Path):
    """è¿è¡Œå®Œæ•´çš„ hOCR ä¼˜åŒ–å®éªŒ"""
    
    print("\n" + "="*70)
    print("ğŸ”¬ hOCR æ–‡ä»¶ä¼˜åŒ–ç ”ç©¶å®éªŒ")
    print("="*70)
    print(f"ğŸ“… æ—¥æœŸ: 2025-10-19")
    print(f"ğŸ¯ ç›®æ ‡: ç ”ç©¶ hOCR æ–‡ä»¶ä¼˜åŒ–ä»¥å‡å°æœ€ç»ˆ PDF å¤§å°")
    print("="*70)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = hocr_file.parent / "hocr_experiments"
    output_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = HocrAnalyzer(hocr_file)
    
    # æ˜¾ç¤ºæ ·æœ¬
    analyzer.show_sample(30)
    
    # åˆ†æç»“æ„
    analysis = analyzer.analyze_structure()
    
    # è¿è¡Œå„ç§ä¼˜åŒ–å®éªŒ
    experiments = []
    
    # å®éªŒ 1: ç©º hOCRï¼ˆåˆ é™¤æ–‡æœ¬ï¼‰
    exp1_file = output_dir / "combined_empty.hocr"
    exp1_path, exp1_size = analyzer.create_empty_hocr(exp1_file)
    experiments.append(('ç©ºæ–‡æœ¬', exp1_size))
    
    # å®éªŒ 2: æœ€å° hOCRï¼ˆåªä¿ç•™ bboxï¼‰
    exp2_file = output_dir / "combined_minimal.hocr"
    exp2_path, exp2_size = analyzer.create_minimal_hocr(exp2_file)
    experiments.append(('æœ€å°åŒ–', exp2_size))
    
    # å®éªŒ 3: æ— å•è¯ hOCR
    exp3_file = output_dir / "combined_no_words.hocr"
    exp3_path, exp3_size = analyzer.create_no_words_hocr(exp3_file)
    experiments.append(('æ— å•è¯', exp3_size))
    
    # å®éªŒ 4: æ— æ–‡æœ¬è¡Œ hOCR
    exp4_file = output_dir / "combined_no_lines.hocr"
    exp4_path, exp4_size = analyzer.create_no_lines_hocr(exp4_file)
    experiments.append(('æ— æ–‡æœ¬è¡Œ', exp4_size))
    
    # æ€»ç»“å¯¹æ¯”
    print("\n" + "="*70)
    print("ğŸ“Š å®éªŒç»“æœå¯¹æ¯”")
    print("="*70)
    print(f"\n{'ç±»å‹':<12} {'å¤§å° (MB)':<12} {'å‡å°‘ (MB)':<12} {'å‡å°‘ç‡':<10}")
    print("-" * 70)
    
    original_mb = analyzer.original_size / 1024 / 1024
    print(f"{'åŸå§‹':<12} {original_mb:<12.2f} {'-':<12} {'-':<10}")
    
    for name, size in experiments:
        size_mb = size / 1024 / 1024
        reduction_mb = (analyzer.original_size - size) / 1024 / 1024
        reduction_pct = (analyzer.original_size - size) / analyzer.original_size * 100
        print(f"{name:<12} {size_mb:<12.2f} {reduction_mb:<12.2f} {reduction_pct:<10.1f}%")
    
    print("\n" + "="*70)
    print("âœ… å®éªŒå®Œæˆï¼æ‰€æœ‰å˜ä½“å·²ä¿å­˜åˆ°:", output_dir)
    print("="*70)
    
    return output_dir, analysis


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python hocr_analyzer.py <hocr_file>")
        print("\nç¤ºä¾‹: python hocr_analyzer.py /tmp/tmpxxx/combined.hocr")
        sys.exit(1)
    
    hocr_file = Path(sys.argv[1])
    
    if not hocr_file.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {hocr_file}")
        sys.exit(1)
    
    run_hocr_experiments(hocr_file)
